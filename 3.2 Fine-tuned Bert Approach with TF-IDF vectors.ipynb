{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Place</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"¡Momias, demasiado impresionante!\"</td>\n",
       "      <td>\"Las momias están en muy buen estado de conser...</td>\n",
       "      <td>Museo de las Momias</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>México</td>\n",
       "      <td>22/10/2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comida cara</td>\n",
       "      <td>Tienen carteles con comida cortida de 40 y no ...</td>\n",
       "      <td>Mercado Hidalgo</td>\n",
       "      <td>N/I</td>\n",
       "      <td>-1</td>\n",
       "      <td>México</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"No coman ahí\"</td>\n",
       "      <td>\"Creo que es muy insalubre, hay basura por tod...</td>\n",
       "      <td>Mercado Hidalgo</td>\n",
       "      <td>Female</td>\n",
       "      <td>61</td>\n",
       "      <td>México</td>\n",
       "      <td>15/01/2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Momificado\"</td>\n",
       "      <td>\"Para mí gusto no vale la pena... tristemente ...</td>\n",
       "      <td>Museo de las Momias</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>11/05/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Incómodo y cero romántico\"</td>\n",
       "      <td>\"Es un lugar poco interesante y que se conoce ...</td>\n",
       "      <td>Callejón del Beso</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>Francia</td>\n",
       "      <td>28/11/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>5192</td>\n",
       "      <td>\"Verdadera joya arquitectónica\"</td>\n",
       "      <td>\"Es una construcción majestuosa, creo que de l...</td>\n",
       "      <td>Teatro Juárez</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>México</td>\n",
       "      <td>24/02/2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5193</td>\n",
       "      <td>\"Romántico\"</td>\n",
       "      <td>\"Muy al estilo de Romeo y Julieta es este siti...</td>\n",
       "      <td>Callejón del Beso</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>31/10/2015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>5194</td>\n",
       "      <td>\"Parece un castillo\"</td>\n",
       "      <td>\"Ideal para subir las escalinatas y divisar su...</td>\n",
       "      <td>Universidad de Guanajuato</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>México</td>\n",
       "      <td>12/11/2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5195</td>\n",
       "      <td>\"Imperdible\"</td>\n",
       "      <td>\"Es imperdible, de ahí puedes ver muy bien la ...</td>\n",
       "      <td>Monumento Pípila</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>Chile</td>\n",
       "      <td>19/05/2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>5196</td>\n",
       "      <td>\"Muy bonita vista\"</td>\n",
       "      <td>\"No te puedes ir de Guanajuato sin visitarlo.....</td>\n",
       "      <td>Monumento Pípila</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>México</td>\n",
       "      <td>26/03/2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5194 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                Title  \\\n",
       "0              0  \"¡Momias, demasiado impresionante!\"   \n",
       "1              1                          Comida cara   \n",
       "2              2                       \"No coman ahí\"   \n",
       "3              3                         \"Momificado\"   \n",
       "4              4          \"Incómodo y cero romántico\"   \n",
       "...          ...                                  ...   \n",
       "5189        5192      \"Verdadera joya arquitectónica\"   \n",
       "5190        5193                          \"Romántico\"   \n",
       "5191        5194                 \"Parece un castillo\"   \n",
       "5192        5195                         \"Imperdible\"   \n",
       "5193        5196                   \"Muy bonita vista\"   \n",
       "\n",
       "                                                Opinion  \\\n",
       "0     \"Las momias están en muy buen estado de conser...   \n",
       "1     Tienen carteles con comida cortida de 40 y no ...   \n",
       "2     \"Creo que es muy insalubre, hay basura por tod...   \n",
       "3     \"Para mí gusto no vale la pena... tristemente ...   \n",
       "4     \"Es un lugar poco interesante y que se conoce ...   \n",
       "...                                                 ...   \n",
       "5189  \"Es una construcción majestuosa, creo que de l...   \n",
       "5190  \"Muy al estilo de Romeo y Julieta es este siti...   \n",
       "5191  \"Ideal para subir las escalinatas y divisar su...   \n",
       "5192  \"Es imperdible, de ahí puedes ver muy bien la ...   \n",
       "5193  \"No te puedes ir de Guanajuato sin visitarlo.....   \n",
       "\n",
       "                          Place  Gender  Age   Country        Date  Label  \n",
       "0           Museo de las Momias    Male   53    México  22/10/2016      1  \n",
       "1               Mercado Hidalgo     N/I   -1    México        2018      1  \n",
       "2               Mercado Hidalgo  Female   61    México  15/01/2013      1  \n",
       "3           Museo de las Momias    Male   38  Colombia  11/05/2017      1  \n",
       "4             Callejón del Beso  Female   38   Francia  28/11/2017      1  \n",
       "...                         ...     ...  ...       ...         ...    ...  \n",
       "5189              Teatro Juárez    Male   68    México  24/02/2017      5  \n",
       "5190          Callejón del Beso    Male   41  Colombia  31/10/2015      5  \n",
       "5191  Universidad de Guanajuato    Male   41    México  12/11/2016      5  \n",
       "5192           Monumento Pípila    Male   46     Chile  19/05/2017      5  \n",
       "5193           Monumento Pípila  Female   31    México  26/03/2016      5  \n",
       "\n",
       "[5194 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/PATH.csv')\n",
    "df.rename(columns={'0': 'Opinion'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2688\n",
       "4    1595\n",
       "3     686\n",
       "2     145\n",
       "1      80\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the labels in the data set\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BETO Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section performs these steps:\n",
    "   \n",
    "- 3.1  Data pre-processing for BETO (removal of quotes from the reviews in the dataframe).\n",
    "    \n",
    "- 3.2 Load the model (BETO) and the tokenizer into memory.\n",
    "\n",
    "- 3.3 Turn the the reviews in the DataFrame into the tokens (imput ids and attention masks) that the model requires for training.\n",
    "\n",
    "- 3.4 Create a DataLoader object for passing the input ids and the attention masks into the model.\n",
    "\n",
    "- 3.5 Pass the tokens through the model.\n",
    "\n",
    "- 3.6 Extract the embeddings created by the model, and save them into a list.\n",
    "\n",
    "- 3.7 Create a Dataframe with these newly created embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the quotes in the text\n",
    "def remove_quotes(dataframe):\n",
    "    clean = []\n",
    "    for op in dataframe['Opinion']:\n",
    "        clean.append(op.strip('\"'))\n",
    "    dataframe['Opinion'] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the quotes in the text inside the Dataframe\n",
    "remove_quotes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load the model (BETO) and the tokenizer into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create the tokenizer and the model (BETO in this case)\n",
    "from transformers import BertModel, BertTokenizer, AdamW\n",
    "\n",
    "model = BertModel.from_pretrained('dccuchile/bert-base-spanish-wwm-cased',\n",
    "                                  output_attentions = False, # The model won't return the attentions weights\n",
    "                                  output_hidden_states = False)\n",
    "model.cuda()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Tokenize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs\n",
    "opiniones = df['Opinion'].values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for opinion in opiniones:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        opinion,                   # Sentence to encode\n",
    "                        add_special_tokens = True, # Add the '[CLS]' and '[SEP]' tokens \n",
    "                        max_length = 512,           # Pad and truncate all sequences\n",
    "                        truncation = True,        \n",
    "                        padding='max_length',\n",
    "                        return_attention_mask = True,  # Get the attention masks\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors\n",
    "                        verbose = True # Print warnings\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Create the DataLoader for feeding the tokens into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataloader for training the model with the tensors created above.\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks)\n",
    "dataloader = DataLoader(\n",
    "            dataset,  \n",
    "            sampler = SequentialSampler(dataset), #Select batches sequentially.\n",
    "            batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Pass the tokens into the model and save the output into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        outputs = model(input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=attention_mask, \n",
    "                        return_dict=True)\n",
    "        output_list.append(outputs.last_hidden_state[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dimensions of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output has 5194 elements, each one corresponding to each sentence in the original dataframe.\n",
      "Each sequence has 512 tokens.\n",
      "Each sentence has a vector with 768 elements in it.\n"
     ]
    }
   ],
   "source": [
    "print(\"The output has\", len(output_list), \"elements, each one corresponding to each sentence in the original dataframe.\")\n",
    "print(\"Each sequence has\", len(output_list[0]), \"tokens.\")\n",
    "print(\"Each sentence has a vector with\", len(output_list[0][0]), \"elements in it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Create a list with the embeddings for each encoded sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for i in range(len(output_list)):\n",
    "    embeddings.append(output_list[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Create a dataframe with the embeddings extracted from BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.100722</td>\n",
       "      <td>-0.513502</td>\n",
       "      <td>-0.111594</td>\n",
       "      <td>0.448818</td>\n",
       "      <td>-0.466021</td>\n",
       "      <td>0.142489</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.030338</td>\n",
       "      <td>-0.365344</td>\n",
       "      <td>-0.200068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>-1.268783</td>\n",
       "      <td>0.053861</td>\n",
       "      <td>0.087202</td>\n",
       "      <td>-0.412110</td>\n",
       "      <td>-0.297560</td>\n",
       "      <td>-0.321638</td>\n",
       "      <td>-1.161446</td>\n",
       "      <td>-0.630026</td>\n",
       "      <td>0.249530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537293</td>\n",
       "      <td>0.437717</td>\n",
       "      <td>0.259103</td>\n",
       "      <td>0.366199</td>\n",
       "      <td>0.062330</td>\n",
       "      <td>0.693132</td>\n",
       "      <td>0.476319</td>\n",
       "      <td>-0.106528</td>\n",
       "      <td>-0.266705</td>\n",
       "      <td>0.396034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104844</td>\n",
       "      <td>-0.971615</td>\n",
       "      <td>-0.640315</td>\n",
       "      <td>-0.127146</td>\n",
       "      <td>-0.314339</td>\n",
       "      <td>-0.237429</td>\n",
       "      <td>0.102838</td>\n",
       "      <td>-0.946722</td>\n",
       "      <td>-0.078620</td>\n",
       "      <td>0.115184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177042</td>\n",
       "      <td>0.283975</td>\n",
       "      <td>-0.306809</td>\n",
       "      <td>-0.246421</td>\n",
       "      <td>-0.075344</td>\n",
       "      <td>0.137682</td>\n",
       "      <td>0.173271</td>\n",
       "      <td>0.732921</td>\n",
       "      <td>-0.387721</td>\n",
       "      <td>-0.271484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418992</td>\n",
       "      <td>-0.690087</td>\n",
       "      <td>-0.420569</td>\n",
       "      <td>0.418654</td>\n",
       "      <td>-0.963163</td>\n",
       "      <td>0.151083</td>\n",
       "      <td>-0.037838</td>\n",
       "      <td>-0.847361</td>\n",
       "      <td>-0.593877</td>\n",
       "      <td>-0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168886</td>\n",
       "      <td>-0.239445</td>\n",
       "      <td>-0.369098</td>\n",
       "      <td>0.286953</td>\n",
       "      <td>0.280967</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>0.244342</td>\n",
       "      <td>-0.246206</td>\n",
       "      <td>-0.279504</td>\n",
       "      <td>-0.197400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081249</td>\n",
       "      <td>-0.327408</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>-0.746119</td>\n",
       "      <td>0.328063</td>\n",
       "      <td>0.077538</td>\n",
       "      <td>-0.805399</td>\n",
       "      <td>-0.040993</td>\n",
       "      <td>0.118009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037849</td>\n",
       "      <td>-0.249693</td>\n",
       "      <td>-0.692661</td>\n",
       "      <td>0.079971</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>-0.024417</td>\n",
       "      <td>-0.464972</td>\n",
       "      <td>-0.335644</td>\n",
       "      <td>-0.578367</td>\n",
       "      <td>-0.438497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262042</td>\n",
       "      <td>-0.947012</td>\n",
       "      <td>0.070426</td>\n",
       "      <td>-0.004722</td>\n",
       "      <td>-0.774869</td>\n",
       "      <td>-0.035387</td>\n",
       "      <td>0.229826</td>\n",
       "      <td>-0.912594</td>\n",
       "      <td>-0.494465</td>\n",
       "      <td>0.863951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>0.427815</td>\n",
       "      <td>-0.066462</td>\n",
       "      <td>-0.182661</td>\n",
       "      <td>-0.182542</td>\n",
       "      <td>-0.367275</td>\n",
       "      <td>0.482871</td>\n",
       "      <td>0.571338</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>-0.570252</td>\n",
       "      <td>-0.295871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107437</td>\n",
       "      <td>-1.077025</td>\n",
       "      <td>0.206952</td>\n",
       "      <td>0.386056</td>\n",
       "      <td>0.578838</td>\n",
       "      <td>-0.270711</td>\n",
       "      <td>0.273910</td>\n",
       "      <td>-0.757631</td>\n",
       "      <td>-0.633818</td>\n",
       "      <td>-0.407240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>0.342039</td>\n",
       "      <td>0.543797</td>\n",
       "      <td>0.486739</td>\n",
       "      <td>0.678449</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>0.245350</td>\n",
       "      <td>0.167865</td>\n",
       "      <td>-0.125825</td>\n",
       "      <td>-0.457089</td>\n",
       "      <td>-0.376417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>-0.488916</td>\n",
       "      <td>-0.016850</td>\n",
       "      <td>-0.120353</td>\n",
       "      <td>-0.037926</td>\n",
       "      <td>-0.950023</td>\n",
       "      <td>0.374648</td>\n",
       "      <td>-0.276405</td>\n",
       "      <td>-0.234301</td>\n",
       "      <td>-0.643547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.867902</td>\n",
       "      <td>0.389410</td>\n",
       "      <td>0.209463</td>\n",
       "      <td>-0.307495</td>\n",
       "      <td>-0.219263</td>\n",
       "      <td>0.111309</td>\n",
       "      <td>0.494184</td>\n",
       "      <td>0.264251</td>\n",
       "      <td>-0.555974</td>\n",
       "      <td>-0.257724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628443</td>\n",
       "      <td>-0.249435</td>\n",
       "      <td>-0.196823</td>\n",
       "      <td>0.326543</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>0.220092</td>\n",
       "      <td>0.472319</td>\n",
       "      <td>-1.158151</td>\n",
       "      <td>0.262810</td>\n",
       "      <td>-0.404702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>0.373302</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>-0.662630</td>\n",
       "      <td>-0.149125</td>\n",
       "      <td>-0.507021</td>\n",
       "      <td>0.360729</td>\n",
       "      <td>0.174792</td>\n",
       "      <td>-0.062389</td>\n",
       "      <td>-0.229902</td>\n",
       "      <td>-1.087377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446199</td>\n",
       "      <td>-1.459899</td>\n",
       "      <td>-0.174872</td>\n",
       "      <td>0.600132</td>\n",
       "      <td>-0.098209</td>\n",
       "      <td>-0.443329</td>\n",
       "      <td>0.161391</td>\n",
       "      <td>-0.469137</td>\n",
       "      <td>0.048491</td>\n",
       "      <td>-0.057459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0.287681</td>\n",
       "      <td>-0.297098</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>0.033331</td>\n",
       "      <td>0.125856</td>\n",
       "      <td>0.150920</td>\n",
       "      <td>0.268070</td>\n",
       "      <td>-0.267265</td>\n",
       "      <td>-0.311788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136408</td>\n",
       "      <td>-0.705088</td>\n",
       "      <td>-0.339523</td>\n",
       "      <td>-0.041942</td>\n",
       "      <td>-0.911518</td>\n",
       "      <td>-0.193209</td>\n",
       "      <td>-0.122045</td>\n",
       "      <td>-0.918832</td>\n",
       "      <td>0.161886</td>\n",
       "      <td>-0.013502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5194 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.100722 -0.513502 -0.111594  0.448818 -0.466021  0.142489  0.228598   \n",
       "1     0.537293  0.437717  0.259103  0.366199  0.062330  0.693132  0.476319   \n",
       "2     0.177042  0.283975 -0.306809 -0.246421 -0.075344  0.137682  0.173271   \n",
       "3     0.168886 -0.239445 -0.369098  0.286953  0.280967  0.066748  0.244342   \n",
       "4     0.037849 -0.249693 -0.692661  0.079971 -0.354050 -0.024417 -0.464972   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5189  0.427815 -0.066462 -0.182661 -0.182542 -0.367275  0.482871  0.571338   \n",
       "5190  0.342039  0.543797  0.486739  0.678449  0.032057  0.245350  0.167865   \n",
       "5191  0.867902  0.389410  0.209463 -0.307495 -0.219263  0.111309  0.494184   \n",
       "5192  0.373302  0.013885 -0.662630 -0.149125 -0.507021  0.360729  0.174792   \n",
       "5193  0.287681 -0.297098  0.169029  0.030012  0.033331  0.125856  0.150920   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     0.030338 -0.365344 -0.200068  ...  0.003040 -1.268783  0.053861   \n",
       "1    -0.106528 -0.266705  0.396034  ...  0.104844 -0.971615 -0.640315   \n",
       "2     0.732921 -0.387721 -0.271484  ...  0.418992 -0.690087 -0.420569   \n",
       "3    -0.246206 -0.279504 -0.197400  ...  0.081249 -0.327408  0.019463   \n",
       "4    -0.335644 -0.578367 -0.438497  ...  0.262042 -0.947012  0.070426   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5189  0.057494 -0.570252 -0.295871  ...  0.107437 -1.077025  0.206952   \n",
       "5190 -0.125825 -0.457089 -0.376417  ...  0.702219 -0.488916 -0.016850   \n",
       "5191  0.264251 -0.555974 -0.257724  ...  0.628443 -0.249435 -0.196823   \n",
       "5192 -0.062389 -0.229902 -1.087377  ...  0.446199 -1.459899 -0.174872   \n",
       "5193  0.268070 -0.267265 -0.311788  ... -0.136408 -0.705088 -0.339523   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0     0.087202 -0.412110 -0.297560 -0.321638 -1.161446 -0.630026  0.249530  \n",
       "1    -0.127146 -0.314339 -0.237429  0.102838 -0.946722 -0.078620  0.115184  \n",
       "2     0.418654 -0.963163  0.151083 -0.037838 -0.847361 -0.593877 -0.005196  \n",
       "3    -0.005029 -0.746119  0.328063  0.077538 -0.805399 -0.040993  0.118009  \n",
       "4    -0.004722 -0.774869 -0.035387  0.229826 -0.912594 -0.494465  0.863951  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5189  0.386056  0.578838 -0.270711  0.273910 -0.757631 -0.633818 -0.407240  \n",
       "5190 -0.120353 -0.037926 -0.950023  0.374648 -0.276405 -0.234301 -0.643547  \n",
       "5191  0.326543  0.046936  0.220092  0.472319 -1.158151  0.262810 -0.404702  \n",
       "5192  0.600132 -0.098209 -0.443329  0.161391 -0.469137  0.048491 -0.057459  \n",
       "5193 -0.041942 -0.911518 -0.193209 -0.122045 -0.918832  0.161886 -0.013502  \n",
       "\n",
       "[5194 rows x 768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_BERT = pd.DataFrame(embeddings)\n",
    "df_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections performs these steps:\n",
    "\n",
    "- 4.1 Create a tokenizer function using Spacy.\n",
    "- 4.2 Create the embeddings using TF-IDF.\n",
    "- 4.3 Get into an array the matrix created by the TF-IDF method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create a tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spanish model for accuracy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_dep_news_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each word using the Spacy tokenizer, and save the tokens into a list\n",
    "def my_tokenizer(sentence):\n",
    "    toks = []\n",
    "    mytokens = nlp(sentence)\n",
    "    for token in mytokens:\n",
    "        toks.append(token.text) \n",
    "    return toks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create the TF-IDF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, lowercase=False)\n",
    "column = vectorizer.fit_transform(df['Opinion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Turn the matrix with the TF-IDF embeddings into a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = column.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Combine the embeddings and pass them through a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5.1 Create a new DataFrame. The columns contain the embeddings (from BETO and the embeddings from TF-IDF), and the rows the indexes that correspond to the reviews in the training set.\n",
    "- 5.2 Train the classifier. In this case, logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Create a new DataFrame with the embeddings from BETO and the embeddings from TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13880</th>\n",
       "      <th>13881</th>\n",
       "      <th>13882</th>\n",
       "      <th>13883</th>\n",
       "      <th>13884</th>\n",
       "      <th>13885</th>\n",
       "      <th>13886</th>\n",
       "      <th>13887</th>\n",
       "      <th>13888</th>\n",
       "      <th>13889</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.100722</td>\n",
       "      <td>-0.513502</td>\n",
       "      <td>-0.111594</td>\n",
       "      <td>0.448818</td>\n",
       "      <td>-0.466021</td>\n",
       "      <td>0.142489</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.030338</td>\n",
       "      <td>-0.365344</td>\n",
       "      <td>-0.200068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537293</td>\n",
       "      <td>0.437717</td>\n",
       "      <td>0.259103</td>\n",
       "      <td>0.366199</td>\n",
       "      <td>0.062330</td>\n",
       "      <td>0.693132</td>\n",
       "      <td>0.476319</td>\n",
       "      <td>-0.106528</td>\n",
       "      <td>-0.266705</td>\n",
       "      <td>0.396034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177042</td>\n",
       "      <td>0.283975</td>\n",
       "      <td>-0.306809</td>\n",
       "      <td>-0.246421</td>\n",
       "      <td>-0.075344</td>\n",
       "      <td>0.137682</td>\n",
       "      <td>0.173271</td>\n",
       "      <td>0.732921</td>\n",
       "      <td>-0.387721</td>\n",
       "      <td>-0.271484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168886</td>\n",
       "      <td>-0.239445</td>\n",
       "      <td>-0.369098</td>\n",
       "      <td>0.286953</td>\n",
       "      <td>0.280967</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>0.244342</td>\n",
       "      <td>-0.246206</td>\n",
       "      <td>-0.279504</td>\n",
       "      <td>-0.197400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037849</td>\n",
       "      <td>-0.249693</td>\n",
       "      <td>-0.692661</td>\n",
       "      <td>0.079971</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>-0.024417</td>\n",
       "      <td>-0.464972</td>\n",
       "      <td>-0.335644</td>\n",
       "      <td>-0.578367</td>\n",
       "      <td>-0.438497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>0.427815</td>\n",
       "      <td>-0.066462</td>\n",
       "      <td>-0.182661</td>\n",
       "      <td>-0.182542</td>\n",
       "      <td>-0.367275</td>\n",
       "      <td>0.482871</td>\n",
       "      <td>0.571338</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>-0.570252</td>\n",
       "      <td>-0.295871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>0.342039</td>\n",
       "      <td>0.543797</td>\n",
       "      <td>0.486739</td>\n",
       "      <td>0.678449</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>0.245350</td>\n",
       "      <td>0.167865</td>\n",
       "      <td>-0.125825</td>\n",
       "      <td>-0.457089</td>\n",
       "      <td>-0.376417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.867902</td>\n",
       "      <td>0.389410</td>\n",
       "      <td>0.209463</td>\n",
       "      <td>-0.307495</td>\n",
       "      <td>-0.219263</td>\n",
       "      <td>0.111309</td>\n",
       "      <td>0.494184</td>\n",
       "      <td>0.264251</td>\n",
       "      <td>-0.555974</td>\n",
       "      <td>-0.257724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>0.373302</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>-0.662630</td>\n",
       "      <td>-0.149125</td>\n",
       "      <td>-0.507021</td>\n",
       "      <td>0.360729</td>\n",
       "      <td>0.174792</td>\n",
       "      <td>-0.062389</td>\n",
       "      <td>-0.229902</td>\n",
       "      <td>-1.087377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0.287681</td>\n",
       "      <td>-0.297098</td>\n",
       "      <td>0.169029</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>0.033331</td>\n",
       "      <td>0.125856</td>\n",
       "      <td>0.150920</td>\n",
       "      <td>0.268070</td>\n",
       "      <td>-0.267265</td>\n",
       "      <td>-0.311788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5194 rows × 14658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0    -0.100722 -0.513502 -0.111594  0.448818 -0.466021  0.142489  0.228598   \n",
       "1     0.537293  0.437717  0.259103  0.366199  0.062330  0.693132  0.476319   \n",
       "2     0.177042  0.283975 -0.306809 -0.246421 -0.075344  0.137682  0.173271   \n",
       "3     0.168886 -0.239445 -0.369098  0.286953  0.280967  0.066748  0.244342   \n",
       "4     0.037849 -0.249693 -0.692661  0.079971 -0.354050 -0.024417 -0.464972   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5189  0.427815 -0.066462 -0.182661 -0.182542 -0.367275  0.482871  0.571338   \n",
       "5190  0.342039  0.543797  0.486739  0.678449  0.032057  0.245350  0.167865   \n",
       "5191  0.867902  0.389410  0.209463 -0.307495 -0.219263  0.111309  0.494184   \n",
       "5192  0.373302  0.013885 -0.662630 -0.149125 -0.507021  0.360729  0.174792   \n",
       "5193  0.287681 -0.297098  0.169029  0.030012  0.033331  0.125856  0.150920   \n",
       "\n",
       "         7         8         9      ...  13880  13881  13882  13883  13884  \\\n",
       "0     0.030338 -0.365344 -0.200068  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1    -0.106528 -0.266705  0.396034  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2     0.732921 -0.387721 -0.271484  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3    -0.246206 -0.279504 -0.197400  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4    -0.335644 -0.578367 -0.438497  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "5189  0.057494 -0.570252 -0.295871  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "5190 -0.125825 -0.457089 -0.376417  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "5191  0.264251 -0.555974 -0.257724  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "5192 -0.062389 -0.229902 -1.087377  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "5193  0.268070 -0.267265 -0.311788  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      13885  13886  13887  13888  13889  \n",
       "0       0.0    0.0    0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0    0.0    0.0  \n",
       "...     ...    ...    ...    ...    ...  \n",
       "5189    0.0    0.0    0.0    0.0    0.0  \n",
       "5190    0.0    0.0    0.0    0.0    0.0  \n",
       "5191    0.0    0.0    0.0    0.0    0.0  \n",
       "5192    0.0    0.0    0.0    0.0    0.0  \n",
       "5193    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5194 rows x 14658 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_embeddings = pd.concat([df_BERT, pd.DataFrame(matrix)], axis=1)\n",
    "df_final_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Train the classifier (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('classifier',\n",
       "                 LogisticRegressionCV(Cs=10, class_weight=None, cv=None,\n",
       "                                      dual=False, fit_intercept=True,\n",
       "                                      intercept_scaling=1.0, l1_ratios=None,\n",
       "                                      max_iter=100, multi_class='auto',\n",
       "                                      n_jobs=None, penalty='l2',\n",
       "                                      random_state=None, refit=True,\n",
       "                                      scoring=None, solver='lbfgs', tol=0.0001,\n",
       "                                      verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules for the logistic regression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a classifier object with multiclass regression\n",
    "classifier = LogisticRegressionCV()\n",
    "\n",
    "# Create a pipeline object\n",
    "pipe = Pipeline([('classifier', classifier)])\n",
    "\n",
    "# Training\n",
    "pipe.fit(df_final_embeddings, df['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Class predictions on the official evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6.1 Load the test set.\n",
    "- 6.2 Pre-process the dataset before doing the prediction of the classes using the model trained above. This includes removing the quotes in the reviews and getting this set's embeddings (as done above).\n",
    "- 6.3 Predict the classes for the reviews.\n",
    "- 6.4 Create the final output file (.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Load the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Place</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Sucio\"</td>\n",
       "      <td>La verdad esperaba mucho más de éste recinto. ...</td>\n",
       "      <td>Casa de Diego Rivera</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1</td>\n",
       "      <td>México</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"NO LO VISITEN LOS 19 DE MARZO CERRADO\"</td>\n",
       "      <td>Guanajuato tiene todo , no podían faltar los m...</td>\n",
       "      <td>Casa de Diego Rivera</td>\n",
       "      <td>N/I</td>\n",
       "      <td>-1</td>\n",
       "      <td>México</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Horrible\"</td>\n",
       "      <td>The Diego Rivera house gives you a good idea o...</td>\n",
       "      <td>Casa de Diego Rivera</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>México</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No vale la pena perder ni un minuto</td>\n",
       "      <td>Interesante. Se pueden apreciar muebles de la ...</td>\n",
       "      <td>Casa de Diego Rivera</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1</td>\n",
       "      <td>N/I</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Ir a Guanajuato y que este cerrado\"</td>\n",
       "      <td>En si hay muy poco de Diego Rivera.. pero quis...</td>\n",
       "      <td>Casa de Diego Rivera</td>\n",
       "      <td>N/I</td>\n",
       "      <td>-1</td>\n",
       "      <td>México</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>2212</td>\n",
       "      <td>\"Históricamente recomendable\"</td>\n",
       "      <td>\"El término alhóndiga proviene del árabe y sig...</td>\n",
       "      <td>Alhóndiga</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>México</td>\n",
       "      <td>2018-05-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2213</td>\n",
       "      <td>\"Vista a Guanajuato\"</td>\n",
       "      <td>\"Conociendo la historia de Juan José de los Re...</td>\n",
       "      <td>Monumento Pípila</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>2018-06-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>2214</td>\n",
       "      <td>\"Increíble vista de Guanajuato\"</td>\n",
       "      <td>\"Fue construida a finales del siglo XVIII, en ...</td>\n",
       "      <td>Alhóndiga</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>México</td>\n",
       "      <td>2018-06-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>2215</td>\n",
       "      <td>\"¡Lugar icónico y romántico!\"</td>\n",
       "      <td>\"Parada obligatoria en tu visita a la ciudad d...</td>\n",
       "      <td>Alhóndiga</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>México</td>\n",
       "      <td>2018-06-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>2216</td>\n",
       "      <td>\"Imponente\"</td>\n",
       "      <td>\"Es un lugar muy tradicional que no puedes dej...</td>\n",
       "      <td>Monumento Pípila</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>México</td>\n",
       "      <td>2018-07-09 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                    Title  \\\n",
       "0         1                                  \"Sucio\"   \n",
       "1         2  \"NO LO VISITEN LOS 19 DE MARZO CERRADO\"   \n",
       "2         3                               \"Horrible\"   \n",
       "3         4      No vale la pena perder ni un minuto   \n",
       "4         5     \"Ir a Guanajuato y que este cerrado\"   \n",
       "...     ...                                      ...   \n",
       "2211   2212            \"Históricamente recomendable\"   \n",
       "2212   2213                     \"Vista a Guanajuato\"   \n",
       "2213   2214          \"Increíble vista de Guanajuato\"   \n",
       "2214   2215            \"¡Lugar icónico y romántico!\"   \n",
       "2215   2216                              \"Imponente\"   \n",
       "\n",
       "                                                Opinion                 Place  \\\n",
       "0     La verdad esperaba mucho más de éste recinto. ...  Casa de Diego Rivera   \n",
       "1     Guanajuato tiene todo , no podían faltar los m...  Casa de Diego Rivera   \n",
       "2     The Diego Rivera house gives you a good idea o...  Casa de Diego Rivera   \n",
       "3     Interesante. Se pueden apreciar muebles de la ...  Casa de Diego Rivera   \n",
       "4     En si hay muy poco de Diego Rivera.. pero quis...  Casa de Diego Rivera   \n",
       "...                                                 ...                   ...   \n",
       "2211  \"El término alhóndiga proviene del árabe y sig...             Alhóndiga   \n",
       "2212  \"Conociendo la historia de Juan José de los Re...      Monumento Pípila   \n",
       "2213  \"Fue construida a finales del siglo XVIII, en ...             Alhóndiga   \n",
       "2214  \"Parada obligatoria en tu visita a la ciudad d...             Alhóndiga   \n",
       "2215  \"Es un lugar muy tradicional que no puedes dej...      Monumento Pípila   \n",
       "\n",
       "      Gender  Age         Country                 Date  \n",
       "0     Female   -1          México                 2016  \n",
       "1        N/I   -1          México                 2016  \n",
       "2       Male   -1          México                 2016  \n",
       "3     Female   -1             N/I                 2016  \n",
       "4        N/I   -1          México                 2016  \n",
       "...      ...  ...             ...                  ...  \n",
       "2211  Female   25          México  2018-05-29 00:00:00  \n",
       "2212  Female   28  Estados Unidos  2018-06-18 00:00:00  \n",
       "2213    Male   59          México  2018-06-19 00:00:00  \n",
       "2214    Male   32          México  2018-06-19 00:00:00  \n",
       "2215    Male   39          México  2018-07-09 00:00:00  \n",
       "\n",
       "[2216 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_excel(\"'/PATH.xlsx\")\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Pre-process the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_quotes(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs\n",
    "opiniones = df_pred['Opinion'].values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for opinion in opiniones:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        opinion,                   \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 512,           \n",
    "                        truncation = True,\n",
    "                        padding='max_length',\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',     \n",
    "                        verbose = True \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Create a DataLoader for training the model with the tensors created above\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks)\n",
    "dataloader = DataLoader(\n",
    "            dataset,  \n",
    "            sampler = SequentialSampler(dataset), # Select the batches sequentially\n",
    "            batch_size = 1)\n",
    "\n",
    "output_list = []\n",
    "for step, batch in enumerate(dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        outputs = model(input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=attention_mask, \n",
    "                        return_dict=True)\n",
    "        output_list.append(outputs.last_hidden_state[0].tolist())\n",
    "        \n",
    "# Create a list with the embeddings from BETO\n",
    "embeddings = []\n",
    "for i in range(len(output_list)):\n",
    "    embeddings.append(output_list[i][0])\n",
    "\n",
    "df_BERT_pred = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13880</th>\n",
       "      <th>13881</th>\n",
       "      <th>13882</th>\n",
       "      <th>13883</th>\n",
       "      <th>13884</th>\n",
       "      <th>13885</th>\n",
       "      <th>13886</th>\n",
       "      <th>13887</th>\n",
       "      <th>13888</th>\n",
       "      <th>13889</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195528</td>\n",
       "      <td>0.156670</td>\n",
       "      <td>-0.443622</td>\n",
       "      <td>0.195192</td>\n",
       "      <td>-0.760902</td>\n",
       "      <td>-0.265523</td>\n",
       "      <td>0.369810</td>\n",
       "      <td>0.474678</td>\n",
       "      <td>-0.663961</td>\n",
       "      <td>-0.641090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.590135</td>\n",
       "      <td>-0.458063</td>\n",
       "      <td>0.175340</td>\n",
       "      <td>0.684648</td>\n",
       "      <td>-0.331125</td>\n",
       "      <td>0.124798</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.546939</td>\n",
       "      <td>-0.789807</td>\n",
       "      <td>-0.194467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.411958</td>\n",
       "      <td>-0.111570</td>\n",
       "      <td>0.235532</td>\n",
       "      <td>-0.402516</td>\n",
       "      <td>0.264954</td>\n",
       "      <td>-0.175784</td>\n",
       "      <td>1.191339</td>\n",
       "      <td>0.508916</td>\n",
       "      <td>-0.873340</td>\n",
       "      <td>-0.054844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.536105</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>-0.320521</td>\n",
       "      <td>-0.369643</td>\n",
       "      <td>0.129396</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.355744</td>\n",
       "      <td>0.210789</td>\n",
       "      <td>-0.140114</td>\n",
       "      <td>-0.426512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451311</td>\n",
       "      <td>-0.205837</td>\n",
       "      <td>0.260806</td>\n",
       "      <td>0.483721</td>\n",
       "      <td>-0.336173</td>\n",
       "      <td>-0.285577</td>\n",
       "      <td>0.681388</td>\n",
       "      <td>0.737064</td>\n",
       "      <td>-0.445331</td>\n",
       "      <td>-0.103577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.589778</td>\n",
       "      <td>-0.028214</td>\n",
       "      <td>-0.127158</td>\n",
       "      <td>-0.427993</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>-0.579404</td>\n",
       "      <td>-0.516421</td>\n",
       "      <td>-0.483683</td>\n",
       "      <td>-0.441637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>1.024327</td>\n",
       "      <td>0.122803</td>\n",
       "      <td>0.160388</td>\n",
       "      <td>-0.130503</td>\n",
       "      <td>-0.410822</td>\n",
       "      <td>-0.270486</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.370058</td>\n",
       "      <td>-0.580365</td>\n",
       "      <td>-0.076135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>0.646842</td>\n",
       "      <td>0.397886</td>\n",
       "      <td>-0.046559</td>\n",
       "      <td>0.182240</td>\n",
       "      <td>-0.777834</td>\n",
       "      <td>-0.474051</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>-0.582197</td>\n",
       "      <td>-0.348780</td>\n",
       "      <td>-0.854576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>0.849721</td>\n",
       "      <td>0.358379</td>\n",
       "      <td>-0.159667</td>\n",
       "      <td>-0.106498</td>\n",
       "      <td>-0.298375</td>\n",
       "      <td>0.457378</td>\n",
       "      <td>0.527721</td>\n",
       "      <td>0.455168</td>\n",
       "      <td>-0.958972</td>\n",
       "      <td>-0.276436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>0.774811</td>\n",
       "      <td>-0.569251</td>\n",
       "      <td>0.136486</td>\n",
       "      <td>0.223525</td>\n",
       "      <td>-0.166071</td>\n",
       "      <td>0.145947</td>\n",
       "      <td>0.301974</td>\n",
       "      <td>0.346886</td>\n",
       "      <td>-0.554392</td>\n",
       "      <td>-0.434842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2216 rows × 14658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     0.195528  0.156670 -0.443622  0.195192 -0.760902 -0.265523  0.369810   \n",
       "1     0.590135 -0.458063  0.175340  0.684648 -0.331125  0.124798  0.532284   \n",
       "2    -0.411958 -0.111570  0.235532 -0.402516  0.264954 -0.175784  1.191339   \n",
       "3     0.536105  0.109472 -0.320521 -0.369643  0.129396  0.469136  0.355744   \n",
       "4     0.451311 -0.205837  0.260806  0.483721 -0.336173 -0.285577  0.681388   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2211  0.198151  0.589778 -0.028214 -0.127158 -0.427993  0.039850 -0.579404   \n",
       "2212  1.024327  0.122803  0.160388 -0.130503 -0.410822 -0.270486  0.014006   \n",
       "2213  0.646842  0.397886 -0.046559  0.182240 -0.777834 -0.474051  0.176925   \n",
       "2214  0.849721  0.358379 -0.159667 -0.106498 -0.298375  0.457378  0.527721   \n",
       "2215  0.774811 -0.569251  0.136486  0.223525 -0.166071  0.145947  0.301974   \n",
       "\n",
       "         7         8         9      ...  13880  13881  13882  13883  13884  \\\n",
       "0     0.474678 -0.663961 -0.641090  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1     0.546939 -0.789807 -0.194467  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2     0.508916 -0.873340 -0.054844  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3     0.210789 -0.140114 -0.426512  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4     0.737064 -0.445331 -0.103577  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "2211 -0.516421 -0.483683 -0.441637  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2212  0.370058 -0.580365 -0.076135  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2213 -0.582197 -0.348780 -0.854576  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2214  0.455168 -0.958972 -0.276436  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2215  0.346886 -0.554392 -0.434842  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      13885  13886  13887  13888  13889  \n",
       "0       0.0    0.0    0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0    0.0    0.0  \n",
       "...     ...    ...    ...    ...    ...  \n",
       "2211    0.0    0.0    0.0    0.0    0.0  \n",
       "2212    0.0    0.0    0.0    0.0    0.0  \n",
       "2213    0.0    0.0    0.0    0.0    0.0  \n",
       "2214    0.0    0.0    0.0    0.0    0.0  \n",
       "2215    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[2216 rows x 14658 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vectorizer object has already been trained, so now we only get the TF-IDF features of the prediction set \n",
    "tfidf_pred = vectorizer.transform(df_pred['Opinion'])\n",
    "matrix_pred = tfidf_pred.toarray()\n",
    "\n",
    "df_final = pd.concat([df_BERT_pred, pd.DataFrame(matrix_pred)], axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Prediction of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe.predict(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Create the final output file (.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame(predictions, columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists that contain the predictions and the indexes of each review\n",
    "classes = []\n",
    "for i in df_output['Label']:\n",
    "    classes.append(str(i))\n",
    "\n",
    "indexes = []\n",
    "for i in range(len(predictions)):\n",
    "    indexes.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final output\n",
    "with open('output_file.txt', 'w') as f:\n",
    "    for clas, i in zip(classes, indexes):\n",
    "        print('\"sentiment\"\\t'+ '\"' + i +  '\"'+ \"\\t\" +  '\"'+ clas +  '\"'+ \"\\n\", file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yourenvironment",
   "language": "python",
   "name": "yourenvironment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
