{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Place</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"¡Momias, demasiado impresionante!\"</td>\n",
       "      <td>\"Las momias están en muy buen estado de conser...</td>\n",
       "      <td>Museo de las Momias</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>México</td>\n",
       "      <td>22/10/2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comida cara</td>\n",
       "      <td>Tienen carteles con comida cortida de 40 y no ...</td>\n",
       "      <td>Mercado Hidalgo</td>\n",
       "      <td>N/I</td>\n",
       "      <td>-1</td>\n",
       "      <td>México</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"No coman ahí\"</td>\n",
       "      <td>\"Creo que es muy insalubre, hay basura por tod...</td>\n",
       "      <td>Mercado Hidalgo</td>\n",
       "      <td>Female</td>\n",
       "      <td>61</td>\n",
       "      <td>México</td>\n",
       "      <td>15/01/2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Momificado\"</td>\n",
       "      <td>\"Para mí gusto no vale la pena... tristemente ...</td>\n",
       "      <td>Museo de las Momias</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>11/05/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Incómodo y cero romántico\"</td>\n",
       "      <td>\"Es un lugar poco interesante y que se conoce ...</td>\n",
       "      <td>Callejón del Beso</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>Francia</td>\n",
       "      <td>28/11/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>5192</td>\n",
       "      <td>\"Verdadera joya arquitectónica\"</td>\n",
       "      <td>\"Es una construcción majestuosa, creo que de l...</td>\n",
       "      <td>Teatro Juárez</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>México</td>\n",
       "      <td>24/02/2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5193</td>\n",
       "      <td>\"Romántico\"</td>\n",
       "      <td>\"Muy al estilo de Romeo y Julieta es este siti...</td>\n",
       "      <td>Callejón del Beso</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>31/10/2015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>5194</td>\n",
       "      <td>\"Parece un castillo\"</td>\n",
       "      <td>\"Ideal para subir las escalinatas y divisar su...</td>\n",
       "      <td>Universidad de Guanajuato</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>México</td>\n",
       "      <td>12/11/2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5195</td>\n",
       "      <td>\"Imperdible\"</td>\n",
       "      <td>\"Es imperdible, de ahí puedes ver muy bien la ...</td>\n",
       "      <td>Monumento Pípila</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>Chile</td>\n",
       "      <td>19/05/2017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>5196</td>\n",
       "      <td>\"Muy bonita vista\"</td>\n",
       "      <td>\"No te puedes ir de Guanajuato sin visitarlo.....</td>\n",
       "      <td>Monumento Pípila</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>México</td>\n",
       "      <td>26/03/2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5194 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                Title  \\\n",
       "0              0  \"¡Momias, demasiado impresionante!\"   \n",
       "1              1                          Comida cara   \n",
       "2              2                       \"No coman ahí\"   \n",
       "3              3                         \"Momificado\"   \n",
       "4              4          \"Incómodo y cero romántico\"   \n",
       "...          ...                                  ...   \n",
       "5189        5192      \"Verdadera joya arquitectónica\"   \n",
       "5190        5193                          \"Romántico\"   \n",
       "5191        5194                 \"Parece un castillo\"   \n",
       "5192        5195                         \"Imperdible\"   \n",
       "5193        5196                   \"Muy bonita vista\"   \n",
       "\n",
       "                                                Opinion  \\\n",
       "0     \"Las momias están en muy buen estado de conser...   \n",
       "1     Tienen carteles con comida cortida de 40 y no ...   \n",
       "2     \"Creo que es muy insalubre, hay basura por tod...   \n",
       "3     \"Para mí gusto no vale la pena... tristemente ...   \n",
       "4     \"Es un lugar poco interesante y que se conoce ...   \n",
       "...                                                 ...   \n",
       "5189  \"Es una construcción majestuosa, creo que de l...   \n",
       "5190  \"Muy al estilo de Romeo y Julieta es este siti...   \n",
       "5191  \"Ideal para subir las escalinatas y divisar su...   \n",
       "5192  \"Es imperdible, de ahí puedes ver muy bien la ...   \n",
       "5193  \"No te puedes ir de Guanajuato sin visitarlo.....   \n",
       "\n",
       "                          Place  Gender  Age   Country        Date  Label  \n",
       "0           Museo de las Momias    Male   53    México  22/10/2016      1  \n",
       "1               Mercado Hidalgo     N/I   -1    México        2018      1  \n",
       "2               Mercado Hidalgo  Female   61    México  15/01/2013      1  \n",
       "3           Museo de las Momias    Male   38  Colombia  11/05/2017      1  \n",
       "4             Callejón del Beso  Female   38   Francia  28/11/2017      1  \n",
       "...                         ...     ...  ...       ...         ...    ...  \n",
       "5189              Teatro Juárez    Male   68    México  24/02/2017      5  \n",
       "5190          Callejón del Beso    Male   41  Colombia  31/10/2015      5  \n",
       "5191  Universidad de Guanajuato    Male   41    México  12/11/2016      5  \n",
       "5192           Monumento Pípila    Male   46     Chile  19/05/2017      5  \n",
       "5193           Monumento Pípila  Female   31    México  26/03/2016      5  \n",
       "\n",
       "[5194 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the official dataset\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('/001/usuarios/juanmvs/anaconda3/NLP/Datos/DatosOficiales.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing quotes \n",
    "def remove_quotes(dataframe):\n",
    "    nw = []\n",
    "    for op in dataframe['Opinion']:\n",
    "        nw.append(op.strip('\"'))\n",
    "    dataframe['Opinion'] = nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the quotes in the reviews\n",
    "remove_quotes(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy for tokenization and part of speech tagging\n",
    "import spacy\n",
    "import spacy_transformers \n",
    "\n",
    "nlp = spacy.load(\"es_dep_news_trf\") # Copied from https://spacy.io/models for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function\n",
    "def my_tokenizer(sentence):\n",
    "    toks = []\n",
    "    mytokens = nlp(sentence)\n",
    "    for token in mytokens:\n",
    "        toks.append(token.text) \n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train (80%) and test (20%) sets\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train['Opinion']\n",
    "y = df_train['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word vectors that will be used for training the models. TFID is selected in this case\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                                 tokenizer=<function my_tokenizer at 0x7f31fd083440>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegressionCV(Cs=10, class_weight=None, cv=None,\n",
       "                                      dual=False, fit_intercept=True,\n",
       "                                      intercept_scaling=1.0, l1_ratios=None,\n",
       "                                      max_iter=100, multi_class='auto',\n",
       "                                      n_jobs=None, penalty='l2',\n",
       "                                      random_state=42, refit=True, scoring=None,\n",
       "                                      solver='lbfgs', tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules for the logistic regression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a classifier object with multiclass regression\n",
    "classifier = LogisticRegressionCV(random_state=42)\n",
    "\n",
    "# Create pipeline using the word vector created above\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "# Model generation\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7238\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for the evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Predicting with the test dataset created above\n",
    "predict = pipe.predict(X_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "mae = mean_absolute_error(y_test, predict)\n",
    "\n",
    "print('MAE: %.4f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE SVM: 0.5592\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for the SVM\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a classifier object\n",
    "classifier = svm.LinearSVC(random_state=42)\n",
    "\n",
    "# Create pipeline using the word vector created above\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "# Model generation\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Prediction \n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "print('MAE SVM: %.4f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function my_tokenizer at 0x7f31fd083440>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary modules for the linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a classifier object \n",
    "classifier = LinearRegression()\n",
    "\n",
    "# Create pipeline using the word vector created above\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "# Model generation\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Linear regression: 0.8499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prediction \n",
    "pred = pipe.predict(X_test)\n",
    "pred = np.rint(pred)\n",
    "\n",
    "# Print the evaluation metric\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "print('MAE Linear regression: %.4f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Linear Regression - ElastNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function my_tokenizer at 0x7f31fd083440>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True,\n",
       "                            l1_ratio=0.9, max_iter=1000, normalize=False,\n",
       "                            positive=False, precompute=False, random_state=42,\n",
       "                            selection='random', tol=0.0001,\n",
       "                            warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create a classifier object \n",
    "classifier = ElasticNet(alpha=0.01, l1_ratio=0.9, selection='random', random_state=42)\n",
    "\n",
    "# Create pipeline using the word vector created above\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "# Model generation\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE ElasticNet regression: 0.7709\n"
     ]
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "pred = np.rint(pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print('MAE ElasticNet regression: %.4f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Linear Regression - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function my_tokenizer at 0x7f31fd083440>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 Lasso(alpha=0.01, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=1000, normalize=False, positive=True,\n",
       "                       precompute=True, random_state=42, selection='random',\n",
       "                       tol=0.0001, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create a classifier object \n",
    "classifier = Lasso(alpha=0.01, precompute=True, positive=True, selection='random', random_state=42)\n",
    "\n",
    "# Create pipeline using the word vector created above\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "# Model generation\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Lasso regression: 0.7709\n"
     ]
    }
   ],
   "source": [
    "pred = pipe.predict(X_test)\n",
    "pred = np.rint(pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print('MAE Lasso regression: %.4f' % mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yourenvironment",
   "language": "python",
   "name": "yourenvironment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
